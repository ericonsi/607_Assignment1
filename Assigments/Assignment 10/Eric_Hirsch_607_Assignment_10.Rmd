---
title: "Eric_Hirsch_607_Assigment_10"
author: "Eric Hirsch"
date: "4/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## {.tabset .tabset-pills}

### Chapter Summary Example

```{r}
#install.packages('tidytext')
#install.packages('textdata')
library(tidytext)
library(tidyverse)
library(janeaustenr)
library(dplyr)
library(stringr)
library(tidyr)
library(wordcloud)
library(reshape2)
library(magrittr)

```



```{r get sentiments}
get_sentiments("afinn")
get_sentiments("bing")
get_sentiments("nrc")

```

### Original Assignment

#### Joy Words In Emma
```{r load Jane Ausitn}

tidy_books <- austen_books() %>%
  group_by(book) %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, 
                                regex("^chapter [\\divxlc]", 
                                      ignore_case = TRUE)))) %>%
  ungroup() %>%
  unnest_tokens(word, text)
```

```{r Get Sentiments - Jane Austin}

nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

tidy_books %>%
  filter(book == "Emma") %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)

```

#### Jane Austin Sentiment Analysis Throughout her Novels

```{r group by sections}


jane_austen_sentiment <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(book, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative)

```

```{r Plot it}

ggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol = 2, scales = "free_x")

```


#### Comparing the Dictionaries

#### Comparing results of Pride and Prejudice

Same peaks and dips but NRC is more positive

```{r}

pride_prejudice <- tidy_books %>% 
  filter(book == "Pride & Prejudice")

pride_prejudice

afinn <- pride_prejudice %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

bing_and_nrc <- bind_rows(
  pride_prejudice %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  pride_prejudice %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)

bind_rows(afinn, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")

```

#### Positive and negative words per lexicon

```{r Pos and ne}

get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive", "negative")) %>% 
  count(sentiment)

get_sentiments("bing") %>% 
  count(sentiment)


```


#### Most Common Postive and Negative Words

```{r}

bing_word_counts <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts

bing_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)
```

#### Add a word to the stop-words list

```{r stop words}

custom_stop_words <- bind_rows(tibble(word = c("miss"),  
                                      lexicon = c("custom")), 
                               stop_words)

custom_stop_words


```

#### Word Clouds

```{r word clouds}

tidy_books %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))

tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)

```

#### Looking at Units Beyond Just Words

```{r sentences}

p_and_p_sentences <- tibble(text = prideprejudice) %>% 
  unnest_tokens(sentence, text, token = "sentences")
p_and_p_sentences$sentence[2]

```

``` {r regex}
austen_chapters <- austen_books() %>%
  group_by(book) %>%
  unnest_tokens(chapter, text, token = "regex", 
                pattern = "Chapter|CHAPTER [\\dIVXLC]") %>%
  ungroup()

austen_chapters %>% 
  group_by(book) %>% 
  summarise(chapters = n())

```

#### We will use tidy text analysis to ask what are the most negative chapters in each of Jane Austenâ€™s novels 

1. Get the list of negative words from the Bing lexicon. 
2. Make a data frame of how many words are in each chapter so we can normalize for the length of chapters. 
3. Find the number of negative words in each chapter and divide by the total words in each chapter. 

```{r  Chapter analysis}

bingnegative <- get_sentiments("bing") %>% 
  filter(sentiment == "negative")

wordcounts <- tidy_books %>%
  group_by(book, chapter) %>%
  summarize(words = n())

tidy_books %>%
  semi_join(bingnegative) %>%
  group_by(book, chapter) %>%
  summarize(negativewords = n()) %>%
  left_join(wordcounts, by = c("book", "chapter")) %>%
  mutate(ratio = negativewords/words) %>%
  filter(chapter != 0) %>%
  slice_max(ratio, n = 1) %>% 
  ungroup()

```

### Sentiment Analysis On Broadway

This dataset, taken from kaggle (link), has synopses and gross receipts for Broadway plays. We will use the package Sentiment Analysis, which contains 4 dictionaries: Harvard-IV, an all-purpose dictionary developed at Harvard, Henry's finance specific dictionary, the Loughran-Macdonald dictionary (another finance dictionary), and the QDAP, which analyses discourse.  Given the specific foci of the latter three databases, we expect the Harvard database to be the most useful.

The SentimentAnalysis package operates differently from the tidytext library - it provides summary statistics for weighted scores which help us determine whether an observation is predominantly positive or negative.

```{r load data}
library(SentimentAnalysis)
dfSynopses<-read.csv("D:/Desk Drawer/Data Science/DataSets/Kaggle Datasets/synopses.csv", fileEncoding="UTF-8-BOM")
dfGrosses<-read.csv("D:/Desk Drawer/Data Science/DataSets/Kaggle Datasets/grosses.csv")


#install.packages('SentimentAnalysis')

```

#### Compare To other dictionaries

The Harvard dictionary has fewer words than the nrc and bing dictionaries.  There is much more parity between positive and negative words in the Harvard dictionary.

```{r}

summary(DictionaryGI)

get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive", "negative")) %>% 
  count(sentiment)

get_sentiments("bing") %>% 
  count(sentiment)
```

#### We compare performance on the 4 dictionaries:

Not surprisingly, the finance dictionaries have medians of 0 - most words do not match the play synopses.  However, while the synopses are not discourse per se, the QDAP analysis and the Harvard analysis are relayively simliar.

```{r jhg}

sentiment <- analyzeSentiment(dfSynopses$synopsis)

table(convertToBinaryResponse(sentiment$SentimentGI))
summary(sentiment$SentimentGI)
ggplot(sentiment, aes(SentimentGI)) +
  geom_histogram() +
  ggtitle("Harvard-IV")

table(convertToBinaryResponse(sentiment$SentimentGI))
summary(sentiment$SentimentHE)
ggplot(sentiment, aes(SentimentHE)) +
  geom_histogram() +
   ggtitle("Henry")


table(convertToBinaryResponse(sentiment$SentimentGI))
summary(sentiment$SentimentLM)
ggplot(sentiment, aes(SentimentLM)) +
  geom_histogram() +
   ggtitle("LM")


table(convertToBinaryResponse(sentiment$SentimentGI))
summary(sentiment$SentimentQDAP)
ggplot(sentiment, aes(SentimentQDAP)) +
  geom_histogram() +
   ggtitle("QDAP") 
```
```{r seats sold}

dfSynopses2 <- cbind(dfSynopses, sentiment)

dfTotalSeats <- dfGrosses %>%
  group_by(show) %>%
  summarise(total_seats_sold  = sum(seats_sold), total_revenues = sum(weekly_gross))

dfJoin <- dfSynopses2 %>% 
  inner_join(dfTotalSeats, by="show") 

dfJoin <- na.omit(dfJoin)

dfSeatAnalysis <- dfJoin %>%
  filter(total_seats_sold<1000000) %>%
  filter(total_revenues>20000000) %>%
  mutate(Valence = case_when(SentimentGI > 0 ~ 'positive',
                           SentimentGI <=0 ~ '0 or negative')) 

```


```{r scatter}

ggplot(dfSeatAnalysis, aes(x =Valence, y=total_seats_sold)) +
  geom_boxplot()

m3 <- lm(total_seats_sold ~ SentimentGI, data = dfSeatAnalysis)
summary(m3)

ggplot(dfSeatAnalysis, aes(SentimentGI, total_seats_sold)) +
  geom_point() +
  stat_smooth(method = "lm", se = FALSE)

ggplot(dfSeatAnalysis, aes(x =Valence, y=total_revenues)) +
  geom_boxplot()

m <- lm(total_revenues ~ SentimentGI, data = dfSeatAnalysis)
summary(m)

ggplot(dfSeatAnalysis, aes(SentimentGI, total_revenues)) +
  geom_point() +
  stat_smooth(method = "lm", se = FALSE)

```

```





