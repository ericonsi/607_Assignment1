---
title: "Eric_Hirsch_607_Project_2"
author: "Eric Hirsch"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-packages, message=FALSE}
library(openintro)
library(tinytex)
library(tidyverse)
library(stringr)
library(magrittr)
library(gridExtra)
library(readxl)
library(kableExtra)
```

# Project 2 
Team members: Eric Hirsch, Dan Sullivan, Cassie Coste

## Introduction 

In this project we will tidy three datasets using TidyR and Dyplr and other handy R tools. After the transformation we will conduct some analyses. This is a joint project with Cassie Coste and Dan Sullivan.  We each cleaned a data set and then showed each other what our challenges were and how we overcame them. This first data set was the data set that I tidied.

### Dataset 1: Bureau of Labor Statistics Data

The data consists of six CSV files from the Bureau of Labor Statistics showing numbers of Americans involved in various occupations and industries, spanning the years 2015 through 2020.  Each file is in the same format. The data set is “wide” – occupations run horizontally and industries run vertically.  

__Challenges with the data set:__
 
  1.	The data set needs to be converted from wide to long, and needs to include a year column and a demographic column.
  2.	The industries which run vertically are repeated six times  - for two genders, three races, and a total. These will need to be collected together.
  3.	The race categories do not add up to the total because they don’t comprise all of the possible races. Therefore an “other race” category will need to calculated and then created.
  4.	The occupations do not appear at the top of the raw data (they appear in the fifth row), which means they need to be extracted and inserted as column headings for the data set.  There are a number of issues with these column headings - for example, they are too long, and they include the insertion of dashes and carriage returns which will need to be removed.
  5.	Some of the rows are summary rows and will need to be removed. In some cases, remaining rows will need to be renamed as they don’t make sense standing alone without the summary row.
  6.	All of the years of the data set need to be appended to the data frame
  7.  The demographic categories (race, gender and total) need to be spread out as columns and arranged in order.


### Dataset 2 - The Upshot - Prison Admissions by County

This dataset is a long dataset used by The Upshot NYT in their article “A Small Indiana County Sends More People to Prison Than San Francisco and Durham, N.C., Combined. Why?” to report on the increase in rural prison populations in recent years.


__Challenges:__

The primary issue with the data set is that it contains years in the variable names for three different variables. The goal is to get to a data set with columns for the three prison admission variables and one for the year. There are also some minor tidying edits such as converting columns to numeric or factor and or removing/adding words to columns or column names. 

As this dataset is only part of the picture that was being looked at by The Upshot, to gain further insight into this dataset and look at some of the things that the article was referring to as well as comments made in the class discussion board, new variables need to be computed and more county data is needed that was not made available by The Upshot. For county data, an additional dataset (2.b) from the US Department of Agriculture (USDA) is joined with The Upshot dataset to perform the final analyses. 

This county dataset had its own set of challenges. There is a rural-urban variable at two time points that is on a 1-9 spectrum and will be re-coded to match Metropolitan/Urban/Rural categories provided by the USDA. When these variables are incorporated into the original dataset, the  rural-urban variable must then be made long through the creation of a new variable using ifelse statements to make sure that prison county data from the 2000s receives the urbanicity variable from the 2000 census and county data from the 2010s receives the urbanicity variable from the 2010 census. 
 
### Dataset 3 - Historic Epidemic Data

Dataset three Uses historic epidemic data as well as estimates and measurements on global population in the form of two separate tables for pre 1950 populations and post 1950 populations. It incorporates these three csv to get estimates on how impactful certain epidemics were based on the total deaths as compared to global population.

__Challenges:__

The biggest challenge with this data was data formation. It contained many pieces of data that were mixed strings and numbers, notes within data points, as well as hyperlink references. Because many columns were not standardized I used a lot of regex to tackle a lot of these issues ultimately paring things down to a point where the values could be standardized and used.

The next challenge was creating a metric to join population data that fluctuated depending on the year. I found population data that was yearly from 1950-2017, by decade from 1900-1950 and every century from 1AD to 1900. Because of this I had to make my own rounding function. where depending on what year the event was it rounded so that population metrics could be added accordingly.


### Tidying Dataset #1: BLS Data


1. First, the first year of data is read into a data frame: 

``` {r load data}
dfBLS_raw <- read.delim("https://raw.githubusercontent.com/ericonsi/CUNY_607/main/Projects/Project%202/bls-2015.csv", sep=",")

```
2. Next, we drop any columns we don't need and add any columns we do.  In this case there is one of each:

  a. Drop the Totals column
  b. Add the Year column

```{r drop totals column and add year}

dfBLS <- dfBLS_raw %>%
  select(-"X") %>%
  mutate(Year = "2015") 
```

3. Now we need to fix the column names (the column names should be the occupations, but they are not because the occupations were not at the top of the file.)  We will need to extract the column names into a vector, clean the names of any extraneous characters and other issues, and use the vector to rename the dataframe columns:

  a. Get a vector for the column names from the row that contains them
  b. Clean the column names by replacing the hyphens and paragraph breaks, taking out unneeded words like 'occupations', etc.
  c. Rename the columns using the vector

```{r columns}

#Extract the names
vColumnNames <- as.character(dfBLS %>%
  filter(row_number() %in% 5) %>%
  select(-contains("Household") & -"Year"))

#Clean the names
vColumnNames = str_replace_all(vColumnNames, "[\r\n]", " ")
vColumnNames = str_replace_all(vColumnNames, "-   ", "")
vColumnNames = str_replace_all(vColumnNames, "- ", "")
vColumnNames = str_replace_all(vColumnNames, "  ", "")
vColumnNames = str_replace_all(vColumnNames, " occupations", "")

#Replace the dataframe names with the extracted names
dfBLS %<>%
  rename(Industry = contains("Household"), !!vColumnNames[1] := X.1, !!vColumnNames[2] := X.2, !!vColumnNames[3] := X.3, !!vColumnNames[4] := X.4, !!vColumnNames[5] := X.5, !!vColumnNames[6] := X.6, !!vColumnNames[7] := X.7, !!vColumnNames[8] := X.8, !!vColumnNames[9] := X.9, !!vColumnNames[10] := X.10, !!vColumnNames[11] := X.11)
```

4. The industries are repeated six times for total, female, male, Black, Asian, and White.  Each of these units will need to be extracted into its own data frame, and the columns gathered into "long" format.  We will also do some cleaning of extraneous rows:

  a. Select rows using 'filter'
  b. Add the relevant demographic info as a column (.e.g Gender or Race)
  c. Handle rows which merely summarize other rows\
    1. Remove the summary row\
    2. Rename the remaining rows where necessary
  c. Gather columns (using handy vector names column) to convert from wide to long
 

```{r filter into demographic units}

DemographicUnit <- function(df, rowStart, rowEnd, demoContent)
{
 
#Extract units based on rows, insert a column with demographic category, remove summary rows and gather the dataframe into long format 
dfNew <- df %>% 
  filter(row_number() %in% rowStart:rowEnd) %>%
  mutate(demog := demoContent) %>%
  filter(Industry !="Manufacturing" & Industry !="Wholesale and retail trade" & Industry !="Other services") %>%
  gather(all_of(vColumnNames),  key="Occupation", value="NumberEmployed")

#The new "NumberEmployed" category needs to be turned into an integer from character. This means removing the comma, and recasting it as an integer. A unique row ID is also created here which will simplify merging the data frame with others.
  dfNew$NumberEmployed = str_replace_all(dfNew$NumberEmployed, ",", "")
  dfNew <- mutate_at(dfNew, vars(NumberEmployed), list(as.integer)) %>%
  mutate(RowID = row_number())

#Some of the rows which were summarized by summary rows need to be reworded.
  dfNew$Industry = str_replace_all(dfNew$Industry, "Durable goods", "Manufacturing, durable goods")
  dfNew$Industry = str_replace_all(dfNew$Industry, "Nondurable goods", "Manufacturing, nondurable goods")
  dfNew$Industry = str_replace_all(dfNew$Industry, "Private households", "Other services, private households only")

return (dfNew)
}

#Each of the units is extracted using the function we've just created
dfBLS_Men = DemographicUnit(dfBLS, 29, 47, "Male")
dfBLS_Women = DemographicUnit(dfBLS, 50, 68, "Female")
dfBLS_White = DemographicUnit(dfBLS, 71, 89, "White")
dfBLS_Black = DemographicUnit(dfBLS, 92, 110, "Black")
dfBLS_Asian = DemographicUnit(dfBLS, 113, 131, "Asian")
dfBLS_Total = DemographicUnit(dfBLS, 8, 26, "Total")

  
```
5. Create the unified dataframe by binding all the race and gender dataframes together:

```{r cr}

dfAll <- rbind(dfBLS_Women, dfBLS_Men, dfBLS_Black, dfBLS_White, dfBLS_Asian, dfBLS_Total)

```

6. Spread the dataframe by demographic unit and create the "Other Race" column by comparing the three race units to the total
  a. Spread the dataframe using TidyR so each demographic unit is a column
  b. Create a category called "Other" which is the Total minus the other ace categories
  d. Create Final dataframe to accept more years
  

```{r Other Race}

dfAll %<>% 
  spread(demog, NumberEmployed) %<>%
  mutate_at(vars(Black, White, Asian, Total), list(as.numeric)) %<>%
  mutate(Other = Total-(Black + White + Asian))

dfFinal <- dfAll
```

This is the last step. We now have a clean data frame in long form. The only thing that remains is using the same steps to read in the other years and appending those dataframes to this.  We do this with a function that brings all of the steps together.  

```{r years}

ReadYear <- function(bls_Year)
{

fileName <- str_c("https://raw.githubusercontent.com/ericonsi/CUNY_607/main/Projects/Project%202/bls-", bls_Year, ".csv")
dfBLS_raw <- read.delim(fileName, sep=",")

dfBLS <- dfBLS_raw %>%
  select(-"X") %>%
  mutate(Year = bls_Year) 

vColumnNames <- as.character(dfBLS %>%
  filter(row_number() %in% 5) %>%
  select(-contains("Household") & -"Year"))

vColumnNames = str_replace_all(vColumnNames, "[\r\n]", " ")
vColumnNames = str_replace_all(vColumnNames, "-   ", "")
vColumnNames = str_replace_all(vColumnNames, "- ", "")
vColumnNames = str_replace_all(vColumnNames, "-", "")
vColumnNames = str_replace_all(vColumnNames, "  ", "")
vColumnNames = str_replace_all(vColumnNames, " occupations", "")

dfBLS %<>%
  rename(Industry = contains("Household"), !!vColumnNames[1] := X.1, !!vColumnNames[2] := X.2, !!vColumnNames[3] := X.3, !!vColumnNames[4] := X.4, !!vColumnNames[5] := X.5, !!vColumnNames[6] := X.6, !!vColumnNames[7] := X.7, !!vColumnNames[8] := X.8, !!vColumnNames[9] := X.9, !!vColumnNames[10] := X.10, !!vColumnNames[11] := X.11)

dfBLS_Men = DemographicUnit(dfBLS, 29, 47, "Male")
dfBLS_Women = DemographicUnit(dfBLS, 50, 68, "Female")
dfBLS_White = DemographicUnit(dfBLS, 71, 89, "White")
dfBLS_Black = DemographicUnit(dfBLS, 92, 110, "Black")
dfBLS_Asian = DemographicUnit(dfBLS, 113, 131, "Asian")
dfBLS_Total = DemographicUnit(dfBLS, 8, 26, "Total")

dfAll <- rbind(dfBLS_Women, dfBLS_Men, dfBLS_Black, dfBLS_White, dfBLS_Asian, dfBLS_Total)

dfAll %<>% 
  spread(demog, NumberEmployed) %<>%
  mutate_at(vars(Black, White, Asian, Total), list(as.numeric)) %<>%
  mutate(Other = Total-(Black + White + Asian))

  return(dfAll)

}

dfs <- ReadYear("2016")
dfFinal <- rbind(dfFinal, dfs)

dfs <- ReadYear("2017")
dfFinal <- rbind(dfFinal, dfs)

dfs <- ReadYear("2018")
dfFinal <- rbind(dfFinal, dfs)

dfs <- ReadYear("2019")
dfFinal <- rbind(dfFinal, dfs)

dfs <- ReadYear("2020")
dfFinal <- rbind(dfFinal, dfs)

dfFinal %<>%
  select("Year", "Industry", "Occupation", "Female", "Male", "Black", "White", "Asian", "Other", "Total")

```
Thus we go from this:

```{r vv}
head(dfBLS_raw,10) %>%
  kbl(caption = "Raw Data - BLS") %>%
  kable_styling(bootstrap_options = c("condensed"))
```
to this:

```{r gfd}
head(dfFinal) %>%
  kbl(caption = "Final Data - BLS") %>%
  kable_styling(bootstrap_options = c("condensed"))
```



### Analysis of Dataset 1: BLS Data

__Task - Name one significant shift in women's employment from traditional occupations/industries to nontraditional from 2015 to 2020.__

Thiswas harder than one might think!

We begin by examining the top 5 occupation/Industry combinations for women in 2015 and 2020.  We can see that the same combinations appear in each year, though the percentages and order change slightly.  These are sectors where women dominate: nannies and maids, education and health, and various office and admin support occupations.

```{r analysis2}
dfFinal <- read.csv("https://raw.githubusercontent.com/ericonsi/CUNY_607/main/Projects/Project%202/Final.csv")
dfFinal <- mutate_at(dfFinal, vars(Year), list(as.character))
dfFinal <- na.omit(dfFinal)
  
df2015 <- dfFinal %>%
  filter(Year=="2015" & Total>100) %>%
  mutate(PercentWomen = Female/Total) %>%
  select(Industry, Occupation, Total, PercentWomen) %>%
  arrange(desc(PercentWomen))
df2015 <- na.omit(df2015)

head(df2015) %>%
  kbl(caption = "Top Occupation/Industries - 2015") %>%
  kable_styling(bootstrap_options = c("condensed"))

df2020 <- dfFinal %>%
  filter(Year=="2020" & Total>100) %>%
  mutate(PercentWomen = Female/Total) %>%
  select(Industry, Occupation, Total, PercentWomen) %>%
  arrange(desc(PercentWomen))
df2020 <- na.omit(df2020)

head(df2020) %>%
  kbl(caption = "Top Occupation/Industries - 2020") %>%
  kable_styling(bootstrap_options = c("condensed"))

```
We can do a deeper dive into occupations and industries by year to see if we can track any significant changes there.

```{r 6}
dfSummary <- dfFinal %>%
  group_by(Occupation, Year) %>%
  summarize(Percent = sum(Female)/sum(Total))

dfSummary <- na.omit(dfSummary)

ggplot(data = dfSummary, aes(x =Occupation, y=Percent, group=Year, fill=Year)) +
  geom_col(position=position_dodge()) + ggtitle("Percent of Women Employed By Occupation") +
  coord_flip() +
  scale_fill_brewer(palette = "Spectral") 
  
  

```

The average percent of women employed in various occupations in the US was very stable from 2105 to 2020.  The only really noticeable shift is in transportation. In most sectors there is little change.  There are some odd outliers - e.g. a large drop in the % of women employed in farming and fishing in 2017. Given the relative stability elsewhere this is probably a shift in how occupations are labeled rather than a real change in the workforce.  

Looking at industries ...

```{r uy}
dfSummary2 <- dfFinal %>%
  group_by(Industry, Year) %>%
  summarize(Percent = sum(Female)/sum(Total))


dfSummary2 <- na.omit(dfSummary2)

ggplot(data = dfSummary2, aes(x =Industry, y=Percent, group=Year, fill=Year)) +
  geom_col(position=position_dodge()) + ggtitle("Percentage of Women Employed By Industry")+
  coord_flip() +
  scale_fill_brewer(palette = "Spectral")


```

Industries show a tiny bit more movement.  Women's % in some traditional industries like nannying and maids fell, and rose slightly in nontraditional ones like construction and mining.

Do these minor industry shifts signify real change?  Let's look at the occupations women are occupying in the mining industry: 

```{r mm}
dfSummary <- dfFinal %>%
  filter(Industry=="Mining, quarrying, and oil and gas extraction") %>%
  group_by(Occupation, Year) %>%
  summarize(Percent = sum(Female)/sum(Total))

dfSummary <- na.omit(dfSummary)

ggplot(data = dfSummary, aes(x =Occupation, y=Percent, group=Year, fill=Year)) +
  geom_col(position=position_dodge()) + ggtitle("Percentage of Women Employed in Mining") +
  coord_flip() +
  scale_fill_brewer(palette = "Spectral")

```

Most of the increase in women's % in mining is in traditional occupations like office, admin, and non-protective services.

We can also circle back to transportation, the occupation in which women have been making the most inroads.  What is happening there?

```{r cv}

dfSummary2 <- dfFinal %>%
  filter(Occupation=="Transportation and material moving") %>%
  group_by(Industry, Year) %>%
  summarize(Percent = sum(Female)/sum(Total))


dfSummary2 <- na.omit(dfSummary2)

ggplot(data = dfSummary2, aes(x =Industry, y=Percent, group=Year, fill=Year)) +
  geom_col(position=position_dodge()) + ggtitle("Percentage of Women in Transportation By Industry")+
  coord_flip() +
  scale_fill_brewer(palette = "Spectral")


```

There appears to be some real movement in women's % of participation in transportation accross many industries.  While mainly in service, education, information and retail, nonetheless women do appear to be making inroads into transportation occupations.  

A google search reveals that in 2016 the DOT launched the Women and Girls Transportation Initiative to increase women' participation in transportation. The initiative appears to have been successful.

While there was little shift of women's percentages in most occupations between 2015 and 2020, transportation does appear to be one area where women made headway in a number of industries.



### Analysis of Dataset 2: Prison Data

The prison dataset was tidied from this:

```{r v886v}
prison_admissions_raw <- as.data.frame(read.delim("https://raw.githubusercontent.com/TheUpshot/prison-admissions/master/county-prison-admissions.csv", 
                                                  header = TRUE, stringsAsFactors = FALSE, sep = ","))


head(prison_admissions_raw) %>%
  kbl(caption = "Raw Data - Prisons") %>%
  kable_styling(bootstrap_options = c("condensed"))
```
to this:

```{r gf6987d}

dfPrisons <- read.csv("https://raw.githubusercontent.com/cassandra-coste/CUNY607/main/prison_df.csv")

head(dfPrisons) %>%
  kbl(caption = "Prison and County Data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

__Task - What states account for the reduction in prison admissions from 2006 to 2014?__


```{r c26885v}

dfPrisons <- mutate_at(dfPrisons, vars(year), list(as.character))
dfPrisons <- na.omit(dfPrisons)

dfSummary2 <- dfPrisons %>%
  group_by(year) %>%
  summarize(Total = sum(prison_admissions))

dfSummary2 <- na.omit(dfSummary2)

ggplot(data = dfSummary2, aes(x =year, y=Total)) +
  geom_col(position=position_dodge()) + ggtitle("Total Prison Admissions by Year")+
  scale_fill_brewer(palette = "Spectral") +
  ylab("Admissions")

```

We can see that overall prison admissions fell from 2006 to 2014.

```{r c23v}

dfSummary2 <- dfPrisons %>%
  group_by(state, year) %>%
  summarize(Total = sum(prison_admissions))

dfSummary2 <- na.omit(dfSummary2)

ggplot(data = dfSummary2, aes(x =state, y=Total, group=year, fill=year)) +
  geom_col(position=position_dodge()) + ggtitle("Total Prison Admissions by State")+
  scale_fill_brewer(palette = "Spectral") +
  ylab("Admissions")

```

The lion's share of decreases came from California - Alabama, Florida, New York and Ohio contributed as well.  There were a few states that gained admissions as well, though the gains were rather small - Arizona, Minnesota, Kentucky, North Carolina, Oklahoma and Pennsylvania.

```{r c265v}

dfCounty <- dfPrisons %>%
  filter(state=="CA") %>%
  group_by(county, urbanicity) %>%
  summarize(Diff = sum(prison_admissions[year=="2006"] - sum(prison_admissions[year=="2014"]))) %>%
  filter(Diff>750)

ggplot(data = dfCounty, aes(x = reorder(county, Diff),  y=Diff)) +
  geom_col(position=position_dodge()) + ggtitle("Decrease in Prison Admissions by CA County, 2006-2014")+
  scale_fill_brewer(palette = "Spectral") +
  coord_flip() +
  ylab("Decrease in Admissions") +
    xlab("County")
```

Many counties in California contributed to the decline, mostly in Southern California which accounted for the 5 counties over 5,000.  Los Angeles, however,  dominated the losses with over 22,000.


```{r qwerd}

ggplot(data = dfCounty, aes(x = reorder(county, Diff),  y=urbanicity)) +
  geom_col(position=position_dodge()) + ggtitle("Counties by 'Urbanicity'")+
  scale_fill_brewer(palette = "Spectral") +
  coord_flip() +
  ylab("Urbanicity") +
  xlab("County")

```

When we look at the "urbancity" of admission declines we see all the counties in California with declines above 750 are urban metropolitan areas.

Thus we conclude that the bulk of admission declines are from California metro areas, especially in Southern California.



### Analysis of Dataset 3: Epidemics

The epidemic dataset was tidied from this:

```{r v6v}
dfepidemic_raw <- as.data.frame(read.delim("https://raw.githubusercontent.com/TheSaltyCrab/Data607-Project2/main/epidemic.csv", 
                                                  header = TRUE, stringsAsFactors = FALSE, sep = ","))


head(dfepidemic_raw) %>%
  kbl(caption = "Raw Data - Epidemics") %>%
  kable_styling(bootstrap_options = c("condensed"))
```
to this:

```{r gf6d}

dfepidemics <- read.csv("https://raw.githubusercontent.com/TheSaltyCrab/Data607-Project2/main/a_clean_epidemic.csv")

head(dfepidemics) %>%
  kbl(caption = "Epidemic - clean") %>%
  kable_styling(bootstrap_options = c("condensed"))
```
__Task - How does the Covid epidemic compare to other epidemics through history?__


```{r xyz}

dfepidemics <- mutate_at(dfepidemics, vars(deaths_low_estimate), list(as.integer))

dfE <- dfepidemics %>%
  select(event, deaths_low_estimate) %>%
  na.omit() %>%
  filter(deaths_low_estimate > 200000)

dfHighlight <- dfE %>%
  filter(event=="COVID-19 pandemic")

ggplot(data = dfE, aes(x = reorder(event, deaths_low_estimate),  y=deaths_low_estimate)) +
  geom_col(position=position_dodge()) + ggtitle("Epidemics by Total Deaths")+
  scale_fill_brewer(palette = "Spectral") +
  coord_flip() +
  geom_col(data=dfHighlight, aes(x=event, y=deaths_low_estimate), color="black", fill="orange") +
  xlab("Event") +
  ylab("Number of Deaths")

```

In terms of total deaths COVID 19 has been very significant (in the top ten) but is dwarfed by some tof the big ones (AIDS, the Black Death and the 1918 Spanish Flu pandemic).  

The dataset does not include population estimates for many years so we will fill NA values with the value above for a proxy.  Then we can calculate % deaths per population for COVID and other events that have no global percentage calculated.

```{r yph}

dfE <- dfepidemics %>% fill(global_population) %>%
   mutate(glob_percent = deaths_low_estimate/global_population*100) %>%
  select(event, glob_percent) %>%
    na.omit() %>%
  filter(glob_percent>.035)

dfHighlight <- dfE %>%
  filter(event=="COVID-19 pandemic")

ggplot(data = dfE, aes(x = reorder(event, glob_percent),  y=glob_percent)) +
  geom_col(position=position_dodge()) + ggtitle("Epidemics by % of Deaths in World Pop")+
  scale_fill_brewer(palette = "Spectral") +
  coord_flip() +
  geom_col(data=dfHighlight, aes(x=event, y=glob_percent), color="orange", fill="orange") +
  xlab("Event") +
  ylab("% of Deaths")

```


In terms of % of global population, COVID is again dwarfed by others but still makes the list at 20.

## Conclusion

The three data sets Cassie, Dan and I chose all had different challenges. My data set had classic issues of wideness, repeating data, etc. Cassie also had a wide data set that needed a reworking of columns and some adding of new columns. Dan had a host of standardization issues – dates, numbers, and text were all written in different formats throughout the data set. Both Cassie and Dan added data from more than one type of data set, and I combined six data sets of the same type from different years.

Working in a team made it possible to learn many different techniques very quickly.  We are all much more advanced in our ability to tidy data.

